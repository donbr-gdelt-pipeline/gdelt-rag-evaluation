# Rule: Certification Challenge â€” Evidence Map & Slide Generator (v4, deliverables/)

## ğŸš« File Safety (Hard Constraints)
- Do **not** read or write outside the current repository.
- Do **not** edit or overwrite `README.md` (no inserts unless explicitly asked with anchors).
- **Only** create or update files under: `/deliverables/`.
- If a required path doesnâ€™t exist, create it.

---

## ğŸ¯ Objective
Produce two concise, gradable artifacts that prove completion of the **7 Certification Challenge tasks** and make grading fast:

1) **/deliverables/CERT_CHECKLIST.md** â€” Selfâ€‘Checklist & Evidence Map  
2) **/deliverables/CERT_SLIDES.md** â€” Presentation outline (intro, 1 slide per task, conclusion)

Use repository content only; if evidence is missing, mark **Partial/No** and specify the missing artifact.

---

## ğŸ“¥ Input Scope
Search only within this repository. Prefer these locations if present:
- `@cert-challenge-grading/cert-challenge-task-list.md` (authoritative tasks)
- `@cert-challenge-grading/cert-challenge-rubric.csv` (grading rubric)
- `@cert-challenge-grading/a16z-llm-app-stack.md` (stack layers reference)
- Top-level files named `README*`, `ARCHITECTURE*`, `DATA*`, `RAGAS*`
- Folders: `/src`, `/app`, `/scripts`, `/docs`, `/data`, `/deliverables`

No external web research.

---

## ğŸ§­ Phase A â€” Selfâ€‘Checklist & Evidence Map
**Output:** Create or update **`/deliverables/CERT_CHECKLIST.md`** with exactly this structure.

### A. Oneâ€‘Screen Summary
- **Project name**
- **1â€‘sentence problem**
- **Primary user**
- **Stack summary** (one tool per a16z layer)
- **Result summary:** naÃ¯ve vs advanced retrieval (1 sentence)

### B. Task Compliance Table
| Task | Status (Yes / Partial / No) | Evidence (file + section) | Scope / Clarity Note | One Improvement |
|------|-----------------------------|---------------------------|----------------------|-----------------|
| 1. Problem & Audience |  |  |  |  |
| 2. Solution & Stack |  |  |  |  |
| 3. Data & Chunking |  |  |  |  |
| 4. Endâ€‘toâ€‘End Prototype |  |  |  |  |
| 5. Golden Test + RAGAS |  |  |  |  |
| 6. Advanced Retrieval |  |  |  |  |
| 7. Performance & Next Steps |  |  |  |  |

**Status Criteria**  
- âœ… **Yes** â€” artifact exists and satisfies rubric item.  
- âš ï¸ **Partial** â€” artifact present but missing a required detail (name what).  
- âŒ **No** â€” artifact absent; specify the smallest missing file/section to add.

**Scope / Clarity Notes**  
- Elements beyond rubric scope (optional/exploration).  
- Features that are unclear or undocumented.  
- Nudge focus back to required artifacts.

### C. Metrics Snapshot (Tasks 5 & 7)
| Strategy | Faithfulness | Response Relevancy | Context Precision | Context Recall |
|----------|--------------|--------------------|-------------------|----------------|
| naive |  |  |  |  |
| advanced |  |  |  |  |

Add exactly two bullets:
- **1 Strength:** what improved most (metric or design choice)  
- **1 Next Step:** concrete actionable improvement

### D. Stack Alignment (a16z LLM App Stack)
| Layer | Tool Used | Why (â‰¤ 12 words) |
|-------|-----------|------------------|
| LLM |  |  |
| Embeddings |  |  |
| Orchestrator |  |  |
| Vector DB |  |  |
| Logging / Eval |  |  |
| Validators |  |  |
| UI / Serving |  |  |

### E. Evidence Details (brief)
For each task: one pointer (file + section/function) and a 1â€‘line summary.

---

## ğŸ Phase B â€” Slide Extractor (Presentation Outline)
**Output:** Create **`/deliverables/CERT_SLIDES.md`** with **9 slides**:

1. **Intro / Hook** â€” context, problem importance, target user  
2. **Task 1 â€” Problem & Audience**  
3. **Task 2 â€” Proposed Solution & Stack**  
4. **Task 3 â€” Data & Chunking**  
5. **Task 4 â€” Endâ€‘toâ€‘End Prototype**  
6. **Task 5 â€” Golden Test Set & RAGAS**  
7. **Task 6 â€” Advanced Retrieval**  
8. **Task 7 â€” Performance & Next Steps**  
9. **Conclusion / Reflection** â€” key results, lessons learned, next iteration

### Slide Template (apply to slides 2â€“8)
```
## Slide N: Task X â€” [Task Name]
**Goal:** [short statement of task requirement]
**Evidence:** [file + section or artifact]
**Result:** [1 sentence on what was achieved]
**Next Step:** [1 sentence improvement or followâ€‘up]
```

### Intro / Conclusion
**Intro:** problem + user (1â€“2 sentences), app name & core idea.  
**Conclusion:** 2â€“3 takeaways, next iteration plan, optional call to action.

---

## ğŸ” Procedure (Deterministic)
1. Locate the task list and rubric in `@cert-challenge-grading/`; otherwise use the canonical 7 labels above.  
2. Scan repo for minimal, direct evidence per task; prefer existing docs over code comments.  
3. Fill the checklist table; when **Partial/No**, write the smallest missing artifact in *One Improvement*.  
4. Build slides strictly: 1 intro, 1 per task, 1 conclusion.  
5. Write files only under `/deliverables/` and exit.

---

## ğŸ§  Tone & Style
- Technical, concise, decisionâ€‘oriented.  
- One sentence per fact where possible.  
- No marketing language, no speculation.

---

## âš¡ Quick Commands (for users)
- â€œGenerate Certification Checklistâ€ â†’ `/deliverables/CERT_CHECKLIST.md`  
- â€œGenerate Slide Outlineâ€ â†’ `/deliverables/CERT_SLIDES.md`  
- â€œList Gaps to Achieve Yesâ€ â†’ print only missing artifacts (paths/sections)
